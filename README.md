# recency-bias
Code and instructions for replicating experiments from ["Linear Recency Bias During Training Improves Transformersâ€™ Fit to Reading Times" (Clark et al., COLING 2025)](https://arxiv.org/abs/2409.11250).

## Pythia-based LM training

[GPT-NeoX](https://github.com/EleutherAI/gpt-neox)

## Surprisal estimation on psycholinguistic corpora

[LLM Surprisal](https://github.com/byungdoh/llm_surprisal)

## Linear mixed-effects regression

[Modelblocks](https://github.com/modelblocks/modelblocks-release)
